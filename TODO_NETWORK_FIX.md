# ðŸ“‹ TODOs: Fix de Actualizaciones Redundantes de Redes

## ðŸŽ¯ Objetivo
Parchear autoswarm para leer las redes desde `Spec.TaskTemplate.Networks` (y/o cachear el Ãºltimo valor aplicado) para que deje de emitir actualizaciones redundantes.

---

## ðŸ“Š Resumen de TODOs

| Fase | TODOs | Tiempo Estimado | Estado |
|------|-------|-----------------|--------|
| **AnÃ¡lisis** | 4 | 30 min | ðŸ”´ Pendiente |
| **DiseÃ±o** | 3 | 20 min | ðŸ”´ Pendiente |
| **Desarrollo** | 5 | 45 min | ðŸ”´ Pendiente |
| **Testing** | 5 | 60 min | ðŸ”´ Pendiente |
| **DocumentaciÃ³n** | 2 | 15 min | ðŸ”´ Pendiente |
| **TOTAL** | **19 TODOs** | **~2.5 horas** | ðŸ”´ 0% |

---

## ðŸ“ TODOs Detallados por Fase

### ðŸ” FASE 1: ANÃLISIS (30 min)

#### â˜ TODO analysis-1: Investigar ubicaciones de redes en Docker Swarm
**DescripciÃ³n**: Verificar dÃ³nde Docker almacena las redes (Spec.Networks vs Spec.TaskTemplate.Networks) despuÃ©s de crear/actualizar servicios

**Acciones**:
- [ ] Crear script de diagnÃ³stico para inspeccionar estructura de Spec
- [ ] Crear servicio de prueba y capturar Spec antes/despuÃ©s de actualizaciÃ³n
- [ ] Documentar diferencias observadas
- [ ] Verificar si el comportamiento es consistente

**Entregable**: Documento con findings sobre ubicaciones de Networks

---

#### â˜ TODO analysis-2: Reproducir el problema
**DescripciÃ³n**: Crear servicio, aplicar redes, verificar logs de reconciliaciÃ³n para confirmar actualizaciones redundantes

**Acciones**:
- [ ] Configurar `AUTOSWARM_LOG_LEVEL=DEBUG`
- [ ] Crear servicio con red Traefik
- [ ] Observar 3-5 ciclos de reconciliaciÃ³n
- [ ] Capturar logs que muestren actualizaciones repetitivas
- [ ] Contar nÃºmero de actualizaciones redundantes

**Entregable**: Logs que evidencian el problema + mÃ©tricas (ej: 5 actualizaciones en 5 min)

---

#### â˜ TODO analysis-3: Revisar documentaciÃ³n Docker API
**DescripciÃ³n**: Entender el comportamiento esperado de Networks en diferentes ubicaciones del Spec

**Acciones**:
- [ ] Leer Docker API docs sobre Service Spec
- [ ] Buscar informaciÃ³n sobre Networks en Spec vs TaskTemplate
- [ ] Verificar si comportamiento estÃ¡ documentado o es bug
- [ ] Consultar issues de docker-py en GitHub

**Entregable**: Resumen de hallazgos de la documentaciÃ³n

---

#### â˜ TODO analysis-4: Identificar puntos de lectura de redes
**DescripciÃ³n**: Encontrar todos los lugares donde se leen current_networks en reconciler.py

**Acciones**:
- [ ] Buscar todas las referencias a `Networks` en el cÃ³digo
- [ ] Identificar otras lecturas similares que puedan tener el mismo problema
- [ ] Verificar si docker_manager.py tiene lecturas similares

**Entregable**: Lista de ubicaciones en el cÃ³digo que necesitan actualizaciÃ³n

---

### ðŸŽ¨ FASE 2: DISEÃ‘O (20 min)

#### â˜ TODO design-1: Definir estrategia de lectura de redes
**DescripciÃ³n**: Decidir si leer de ambas ubicaciones, prioridad de lectura, o implementar cache

**Acciones**:
- [ ] Evaluar OpciÃ³n 1: Lectura dual (Spec.Networks + TaskTemplate.Networks)
- [ ] Evaluar OpciÃ³n 2: Cache de Ãºltimo valor aplicado
- [ ] Evaluar OpciÃ³n 3: HÃ­brida (dual + cache)
- [ ] Documentar pros/contras de cada opciÃ³n
- [ ] **DECISIÃ“N**: Seleccionar estrategia a implementar

**Entregable**: Documento de decisiÃ³n tÃ©cnica

---

#### â˜ TODO design-2: DiseÃ±ar funciÃ³n get_current_networks()
**DescripciÃ³n**: Crear mÃ©todo que lea de Spec.Networks y/o Spec.TaskTemplate.Networks con fallback inteligente

**Acciones**:
- [ ] Definir firma de la funciÃ³n
- [ ] Especificar parÃ¡metros de entrada
- [ ] Definir valor de retorno
- [ ] Documentar lÃ³gica de prioridad/fallback
- [ ] Crear pseudocÃ³digo

**Entregable**: DiseÃ±o detallado de la funciÃ³n con pseudocÃ³digo

---

#### â˜ TODO design-3: Evaluar necesidad de cache
**DescripciÃ³n**: Determinar si cachear Ãºltimo valor aplicado mejora la soluciÃ³n o si lectura dual es suficiente

**Acciones**:
- [ ] Analizar si lectura dual resuelve 100% del problema
- [ ] Evaluar overhead de implementar cache
- [ ] Considerar edge cases (restart del agente, etc.)
- [ ] **DECISIÃ“N**: Implementar cache o no

**Entregable**: DecisiÃ³n documentada sobre implementaciÃ³n de cache

---

### ðŸ’» FASE 3: DESARROLLO (45 min)

#### â˜ TODO dev-1: Implementar get_current_networks() en Reconciler
**DescripciÃ³n**: MÃ©todo que lee redes de Spec.Networks, TaskTemplate.Networks, o ambos

**UbicaciÃ³n**: `src/reconciler.py` (nueva funciÃ³n en clase Reconciler)

**CÃ³digo esperado**:
```python
def get_current_networks(self, service_spec: Dict) -> List[Dict[str, str]]:
    """
    Obtiene las redes actuales del servicio desde mÃºltiples ubicaciones.

    Docker Swarm puede almacenar redes en:
    - Spec.Networks (nivel de servicio)
    - Spec.TaskTemplate.Networks (nivel de tarea, donde Docker las mueve)

    Returns:
        Lista de configuraciones de red actuales
    """
    # ImplementaciÃ³n aquÃ­
```

**Entregable**: FunciÃ³n implementada y funcionando

---

#### â˜ TODO dev-2: Actualizar reconcile_application()
**DescripciÃ³n**: Reemplazar lÃ­nea 127 para usar get_current_networks() en lugar de lectura directa

**UbicaciÃ³n**: `src/reconciler.py`, lÃ­nea ~127

**Cambio**:
```python
# ANTES:
current_networks = service_spec.get("Networks") or []

# DESPUÃ‰S:
current_networks = self.get_current_networks(service_spec)
```

**Entregable**: CÃ³digo actualizado en reconcile_application()

---

#### â˜ TODO dev-3: Mejorar logging
**DescripciÃ³n**: Agregar logs DEBUG que muestren dÃ³nde se encontraron las redes actuales y por quÃ© se considera necesaria actualizaciÃ³n

**UbicaciÃ³n**: `src/reconciler.py`, funciÃ³n get_current_networks() y reconcile_application()

**Logs a agregar**:
```python
LOGGER.debug(
    "Service '%s' networks - Spec: %s, TaskTemplate: %s, Using: %s",
    service_name, spec_nets, task_nets, current_networks
)

LOGGER.debug(
    "Service '%s' network comparison - Current: %s, Desired: %s, Needs update: %s",
    service.name, current_networks, desired_networks, needs_network_update
)
```

**Entregable**: Logging mejorado para debugging

---

#### â˜ TODO dev-4: (Opcional) Implementar cache de redes aplicadas
**DescripciÃ³n**: Si se decide por cache, implementar diccionario {service_name: networks} con timestamp

**CondiciÃ³n**: Solo si design-3 decide implementar cache

**UbicaciÃ³n**: `src/reconciler.py`, clase Reconciler

**Estructura**:
```python
class Reconciler:
    def __init__(self, ...):
        # ... existente ...
        self._applied_networks_cache: Dict[str, List[Dict]] = {}
        self._cache_timestamps: Dict[str, float] = {}
        self._cache_ttl = 300  # 5 minutos
```

**Entregable**: Cache implementado (si aplicable)

---

#### â˜ TODO dev-5: Agregar validaciÃ³n de normalizaciÃ³n
**DescripciÃ³n**: Asegurar que ambas representaciones de redes se normalicen al mismo formato antes de comparar

**UbicaciÃ³n**: `src/reconciler.py`, funciÃ³n service_networks_match()

**Acciones**:
- [ ] Verificar que formato de redes sea consistente
- [ ] Normalizar claves (mayÃºsculas/minÃºsculas)
- [ ] Manejar orden de redes (si es relevante)
- [ ] Considerar aliases opcionales

**Entregable**: ComparaciÃ³n de redes robusta y normalizada

---

### ðŸ§ª FASE 4: TESTING (60 min)

#### â˜ TODO test-1: Crear test unitario para get_current_networks()
**DescripciÃ³n**: Probar lectura desde Spec.Networks, TaskTemplate.Networks, y escenarios de fallback

**UbicaciÃ³n**: Crear `tests/test_reconciler_networks.py`

**Casos de prueba**:
```python
def test_get_current_networks_from_spec():
    """Redes solo en Spec.Networks"""

def test_get_current_networks_from_task_template():
    """Redes solo en TaskTemplate.Networks"""

def test_get_current_networks_both_locations():
    """Redes en ambos lugares - debe priorizar TaskTemplate"""

def test_get_current_networks_empty():
    """Sin redes en ninguna ubicaciÃ³n"""
```

**Entregable**: Tests unitarios con 100% coverage de la funciÃ³n

---

#### â˜ TODO test-2: Test de integraciÃ³n
**DescripciÃ³n**: Crear servicio, reconciliar, verificar que no genere segunda actualizaciÃ³n redundante

**UbicaciÃ³n**: `tests/integration/test_network_reconciliation.py`

**Flujo**:
```python
def test_no_redundant_network_updates():
    # 1. Crear servicio con red Traefik
    # 2. Primera reconciliaciÃ³n (debe actualizar si necesario)
    # 3. Capturar nÃºmero de actualizaciones
    # 4. Segunda reconciliaciÃ³n (NO debe actualizar)
    # 5. Tercera reconciliaciÃ³n (NO debe actualizar)
    # 6. Assert: solo 1 actualizaciÃ³n en total
```

**Entregable**: Test de integraciÃ³n que valida el fix

---

#### â˜ TODO test-3: Verificar logs
**DescripciÃ³n**: Confirmar que logs DEBUG muestran correctamente detecciÃ³n de redes y decisiones de actualizaciÃ³n

**Acciones**:
- [ ] Ejecutar con `AUTOSWARM_LOG_LEVEL=DEBUG`
- [ ] Crear servicio y observar logs
- [ ] Verificar que muestra dÃ³nde encontrÃ³ las redes
- [ ] Verificar que explica decisiÃ³n de update/no-update
- [ ] Confirmar claridad de mensajes

**Entregable**: Logs verificados y validados

---

#### â˜ TODO test-4: Test con mÃºltiples redes
**DescripciÃ³n**: Verificar comportamiento con servicios que tienen mÃºltiples redes overlay incluyendo Traefik

**Escenario**:
```python
def test_multiple_networks():
    # Servicio con:
    # - Red Traefik
    # - Red de aplicaciÃ³n custom
    # - Red de base de datos
    # Verificar detecciÃ³n correcta de todas
```

**Entregable**: Test con mÃºltiples redes funcionando

---

#### â˜ TODO test-5: Test de regresiÃ³n
**DescripciÃ³n**: Ejecutar suite completa para asegurar que el parche no rompe funcionalidad existente

**Acciones**:
- [ ] Ejecutar todos los tests existentes
- [ ] Ejecutar `python verify_refactor.py`
- [ ] Verificar que no hay regresiones
- [ ] Validar mÃ©tricas de performance

**Entregable**: Suite de tests pasando al 100%

---

### ðŸ“š FASE 5: DOCUMENTACIÃ“N (15 min)

#### â˜ TODO doc-1: Documentar comportamiento de Docker Swarm
**DescripciÃ³n**: Agregar comentarios explicando por quÃ© se leen redes de mÃºltiples ubicaciones

**UbicaciÃ³n**: `src/reconciler.py`, funciÃ³n get_current_networks()

**Contenido del comentario**:
```python
"""
Obtiene las redes actuales del servicio desde mÃºltiples ubicaciones.

CONTEXTO:
Docker Swarm tiene un comportamiento donde las redes pueden estar en
diferentes ubicaciones del Spec dependiendo del momento:

1. Al crear/actualizar: Las redes se especifican en Spec.Networks
2. DespuÃ©s de aplicar: Docker puede mover las redes a Spec.TaskTemplate.Networks

Si solo leemos de Spec.Networks, podemos no encontrar redes que ya estÃ¡n
aplicadas, causando actualizaciones redundantes.

SOLUCIÃ“N:
Esta funciÃ³n lee de ambas ubicaciones y prioriza TaskTemplate.Networks
cuando estÃ¡ disponible, ya que representa el estado efectivo del servicio.

Ver: NETWORK_RECONCILIATION_FIX.md para mÃ¡s detalles.
"""
```

**Entregable**: CÃ³digo bien documentado

---

#### â˜ TODO doc-2: Actualizar ARCHITECTURE.md
**DescripciÃ³n**: Documentar la soluciÃ³n al problema de actualizaciones redundantes

**UbicaciÃ³n**: `ARCHITECTURE.md`

**SecciÃ³n a agregar**:
```markdown
### Fix: ReconciliaciÃ³n de Redes

**Problema**: Actualizaciones redundantes debido a lectura incorrecta de redes.

**SoluciÃ³n**: Lectura dual de `Spec.Networks` y `Spec.TaskTemplate.Networks`.

**Detalles**: Ver `NETWORK_RECONCILIATION_FIX.md`
```

**Entregable**: ARCHITECTURE.md actualizado

---

## ðŸŽ¯ Criterios de AceptaciÃ³n

Para considerar este trabajo COMPLETO, se deben cumplir:

- [x] âœ… Todos los 19 TODOs completados
- [ ] âœ… Tests unitarios pasando (coverage > 90%)
- [ ] âœ… Tests de integraciÃ³n pasando
- [ ] âœ… Logs muestran 0 actualizaciones redundantes en prueba de 5 ciclos
- [ ] âœ… DocumentaciÃ³n actualizada y clara
- [ ] âœ… Code review aprobado
- [ ] âœ… Deploy exitoso sin regresiones

---

## ðŸ“ˆ Progreso

```
Progreso: [â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 0% (0/19 completados)

Estado por fase:
  AnÃ¡lisis:       [â–‘â–‘â–‘â–‘] 0/4
  DiseÃ±o:         [â–‘â–‘â–‘] 0/3
  Desarrollo:     [â–‘â–‘â–‘â–‘â–‘] 0/5
  Testing:        [â–‘â–‘â–‘â–‘â–‘] 0/5
  DocumentaciÃ³n:  [â–‘â–‘] 0/2
```

---

## ðŸš€ PrÃ³ximos Pasos

1. **Iniciar analysis-1**: Crear script de diagnÃ³stico
2. Ejecutar anÃ¡lisis completo (30 min)
3. Proceder a diseÃ±o
4. Implementar soluciÃ³n
5. Validar con tests
6. Documentar y desplegar

---

**Creado**: 2025-10-22
**Estimado**: 2.5 horas
**Prioridad**: Alta
**Asignado**: Equipo Autoswarm

